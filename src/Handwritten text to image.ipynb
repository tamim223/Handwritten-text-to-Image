{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.7.12","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"markdown","source":"# Extraction of Handwritten Text\n\n## Project Synopsis\nOne of the most difficult tasks in NLP is handwriting. It's because it can differ from person to person. However, certain characters (for example, English) are very similar. We use contextualized information and lexical matching as a human starting point.\nWhile humans have the ability to determine whether it is \"O\" or \"0\" from contextualised information, \"O\" can sometimes be written as \"0.\" For instance, \"0\" will be used in phone numbers, whereas \"O\" will be part of an English word. Searching the lexicon is another talent. Even if we don't recognise every single character, it helps us guess words.\nHere I seek to classify individual words so the word can be converted into a digital form. Firstly, I took a dataset from Kaggle containing around 50000 handwritten words. Then I process and prepare the data for training and in the process, I remove the unreadable images. After processing the data and labels, I made a CRNN model which will use CNN and RNN sequentially. The model was then trained and checked for performance on the validation set. Finally, I took some custom inputs to check and the text was recognized with ease.\n\n![Diagram](https://media.discordapp.net/attachments/764117206350823464/929590539505008650/HTR_Diagram.png?width=860&height=598)","metadata":{}},{"cell_type":"markdown","source":"## **Importing the necessary libraries.**","metadata":{}},{"cell_type":"code","source":"import os\nimport cv2\nimport random\nimport numpy as np\nimport pandas as pd\nimport matplotlib.pyplot as plt\n\nimport tensorflow as tf\nfrom keras import backend as K\nfrom keras.models import Model\nfrom keras.layers import Input, Conv2D, MaxPooling2D, Reshape, Bidirectional, LSTM, Dense, Lambda, Activation, BatchNormalization, Dropout\nfrom keras.optimizers import Adam","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## **Load and view data**","metadata":{}},{"cell_type":"code","source":"train = pd.read_csv('/kaggle/input/handwriting-recognition/written_name_train_v2.csv')\nvalid = pd.read_csv('/kaggle/input/handwriting-recognition/written_name_validation_v2.csv')","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"plt.figure(figsize=(15, 10))\n\nfor i in range(6):\n    ax = plt.subplot(2, 3, i+1)\n    img_dir = '/kaggle/input/handwriting-recognition/train_v2/train/'+train.loc[i, 'FILENAME']\n    image = cv2.imread(img_dir, cv2.IMREAD_GRAYSCALE)\n    plt.imshow(image, cmap = 'gray')\n    plt.title(train.loc[i, 'IDENTITY'], fontsize=12)\n    plt.axis('off')\n\nplt.subplots_adjust(wspace=0.2, hspace=-0.8)","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## **Cleaning Data**","metadata":{}},{"cell_type":"markdown","source":"Let's check for NaNs in our label.","metadata":{}},{"cell_type":"code","source":"print(\"Number of NaNs in train set      : \", train['IDENTITY'].isnull().sum())\nprint(\"Number of NaNs in validation set : \", valid['IDENTITY'].isnull().sum())","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"train.dropna(axis=0, inplace=True)\nvalid.dropna(axis=0, inplace=True)","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"Also, there are some images in our data with the label 'UNREADABLE'. Lets check those images and remove them.","metadata":{}},{"cell_type":"code","source":"unreadable = train[train['IDENTITY'] == 'UNREADABLE']\nunreadable.reset_index(inplace = True, drop=True)\n\nplt.figure(figsize=(15, 10))\n\nfor i in range(6):\n    ax = plt.subplot(2, 3, i+1)\n    img_dir = '/kaggle/input/handwriting-recognition/train_v2/train/'+unreadable.loc[i, 'FILENAME']\n    image = cv2.imread(img_dir, cv2.IMREAD_GRAYSCALE)\n    plt.imshow(image, cmap = 'gray')\n    plt.title(unreadable.loc[i, 'IDENTITY'], fontsize=12)\n    plt.axis('off')\n\nplt.subplots_adjust(wspace=0.2, hspace=-0.8)","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"train = train[train['IDENTITY'] != 'UNREADABLE']\nvalid = valid[valid['IDENTITY'] != 'UNREADABLE']","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"There are some labels which are in lowercase. To maintain uniformity in the labels, I convert all the labels to uppercase.","metadata":{}},{"cell_type":"code","source":"train['IDENTITY'] = train['IDENTITY'].str.upper()\nvalid['IDENTITY'] = valid['IDENTITY'].str.upper()","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"Reset the index and we are done with cleaning.","metadata":{}},{"cell_type":"code","source":"train.reset_index(inplace = True, drop=True) \nvalid.reset_index(inplace = True, drop=True)","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## **Preprocessing and preparing the images for training**","metadata":{}},{"cell_type":"code","source":"def preprocess(img):\n    (h, w) = img.shape\n    \n    final_img = np.ones([64, 256])*255 # blank white image\n    \n    # crop\n    if w > 256:\n        img = img[:, :256]\n        \n    if h > 64:\n        img = img[:64, :]\n    \n    \n    final_img[:h, :w] = img\n    return cv2.rotate(final_img, cv2.ROTATE_90_CLOCKWISE)","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"The model will be trained on 30000 images and validate on 3000 images","metadata":{}},{"cell_type":"code","source":"train_size = 30000\nvalid_size= 3000","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"train_x = []\n\nfor i in range(train_size):\n    img_dir = '/kaggle/input/handwriting-recognition/train_v2/train/'+train.loc[i, 'FILENAME']\n    image = cv2.imread(img_dir, cv2.IMREAD_GRAYSCALE)\n    image = preprocess(image)\n    image = image/255.\n    train_x.append(image)","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"valid_x = []\n\nfor i in range(valid_size):\n    img_dir = '/kaggle/input/handwriting-recognition/validation_v2/validation/'+valid.loc[i, 'FILENAME']\n    image = cv2.imread(img_dir, cv2.IMREAD_GRAYSCALE)\n    image = preprocess(image)\n    image = image/255.\n    valid_x.append(image)","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"train_x = np.array(train_x).reshape(-1, 256, 64, 1)\nvalid_x = np.array(valid_x).reshape(-1, 256, 64, 1)","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## **Preparing the labels for CTC Loss**\n\nThe labels have to be converted to numbers which represent each character in the training set. The 'alphabets' consist of A-Z and three special characters (-  '  and space).","metadata":{}},{"cell_type":"code","source":"alphabets = u\"ABCDEFGHIJKLMNOPQRSTUVWXYZ-' \"\nmax_str_len = 24 # max length of input labels\nnum_of_characters = len(alphabets) + 1 # +1 for ctc pseudo blank\nnum_of_timestamps = 64 # max length of predicted labels\n\n\ndef label_to_num(label):\n    label_num = []\n    for ch in label:\n        label_num.append(alphabets.find(ch))\n        \n    return np.array(label_num)\n\ndef num_to_label(num):\n    ret = \"\"\n    for ch in num:\n        if ch == -1:  # CTC Blank\n            break\n        else:\n            ret+=alphabets[ch]\n    return ret","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"name = 'JEBASTIN'\nprint(name, '\\n',label_to_num(name))","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"* **train_y** contains the true labels converted to numbers and padded with -1. The length of each label is equal to max_str_len. \n* **train_label_len** contains the length of each true label (without padding) \n* **train_input_len** contains the length of each predicted label. The length of all the predicted labels is constant i.e number of timestamps - 2.  \n* **train_output** is a dummy output for ctc loss. ","metadata":{}},{"cell_type":"code","source":"train_y = np.ones([train_size, max_str_len]) * -1\ntrain_label_len = np.zeros([train_size, 1])\ntrain_input_len = np.ones([train_size, 1]) * (num_of_timestamps-2)\ntrain_output = np.zeros([train_size])\n\nfor i in range(train_size):\n    train_label_len[i] = len(train.loc[i, 'IDENTITY'])\n    train_y[i, 0:len(train.loc[i, 'IDENTITY'])]= label_to_num(train.loc[i, 'IDENTITY'])  ","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"valid_y = np.ones([valid_size, max_str_len]) * -1\nvalid_label_len = np.zeros([valid_size, 1])\nvalid_input_len = np.ones([valid_size, 1]) * (num_of_timestamps-2)\nvalid_output = np.zeros([valid_size])\n\nfor i in range(valid_size):\n    valid_label_len[i] = len(valid.loc[i, 'IDENTITY'])\n    valid_y[i, 0:len(valid.loc[i, 'IDENTITY'])]= label_to_num(valid.loc[i, 'IDENTITY'])  ","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"print('True label : ',train.loc[100, 'IDENTITY'] , '\\ntrain_y : ',train_y[100],'\\ntrain_label_len : ',train_label_len[100], \n      '\\ntrain_input_len : ', train_input_len[100])","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## **Building our model**","metadata":{}},{"cell_type":"code","source":"input_data = Input(shape=(256, 64, 1), name='input')\n\ninner = Conv2D(32, (3, 3), padding='same', name='conv1', kernel_initializer='he_normal')(input_data)  \ninner = BatchNormalization()(inner)\ninner = Activation('relu')(inner)\ninner = MaxPooling2D(pool_size=(2, 2), name='max1')(inner)\n\ninner = Conv2D(64, (3, 3), padding='same', name='conv2', kernel_initializer='he_normal')(inner)\ninner = BatchNormalization()(inner)\ninner = Activation('relu')(inner)\ninner = MaxPooling2D(pool_size=(2, 2), name='max2')(inner)\ninner = Dropout(0.3)(inner)\n\ninner = Conv2D(128, (3, 3), padding='same', name='conv3', kernel_initializer='he_normal')(inner)\ninner = BatchNormalization()(inner)\ninner = Activation('relu')(inner)\ninner = MaxPooling2D(pool_size=(1, 2), name='max3')(inner)\ninner = Dropout(0.3)(inner)\n\n# CNN to RNN\ninner = Reshape(target_shape=((64, 1024)), name='reshape')(inner)\ninner = Dense(64, activation='relu', kernel_initializer='he_normal', name='dense1')(inner)\n\n## RNN\ninner = Bidirectional(LSTM(256, return_sequences=True), name = 'lstm1')(inner)\ninner = Bidirectional(LSTM(256, return_sequences=True), name = 'lstm2')(inner)\n\n## OUTPUT\ninner = Dense(num_of_characters, kernel_initializer='he_normal',name='dense2')(inner)\ny_pred = Activation('softmax', name='softmax')(inner)\n\nmodel = Model(inputs=input_data, outputs=y_pred)\nmodel.summary()","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"The output shape of the predictions is (64, 30). The model predicts words of 64 characters and each character contains the probability of the 30 alphabets which we defined earlier.","metadata":{}},{"cell_type":"code","source":"# the ctc loss function\ndef ctc_lambda_func(args):\n    y_pred, labels, input_length, label_length = args\n    # the 2 is critical here since the first couple outputs of the RNN\n    # tend to be garbage\n    y_pred = y_pred[:, 2:, :]\n    return K.ctc_batch_cost(labels, y_pred, input_length, label_length)","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"labels = Input(name='gtruth_labels', shape=[max_str_len], dtype='float32')\ninput_length = Input(name='input_length', shape=[1], dtype='int64')\nlabel_length = Input(name='label_length', shape=[1], dtype='int64')\n\nctc_loss = Lambda(ctc_lambda_func, output_shape=(1,), name='ctc')([y_pred, labels, input_length, label_length])\nmodel_final = Model(inputs=[input_data, labels, input_length, label_length], outputs=ctc_loss)","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## **Train our model**","metadata":{}},{"cell_type":"code","source":"# the loss calculation occurs elsewhere, so we use a dummy lambda function for the loss\nmodel_final.compile(loss={'ctc': lambda y_true, y_pred: y_pred}, optimizer=Adam(lr = 0.0001))\n\nmodel_final.fit(x=[train_x, train_y, train_input_len, train_label_len], y=train_output, \n                validation_data=([valid_x, valid_y, valid_input_len, valid_label_len], valid_output),\n                epochs=60, batch_size=128)","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## **Check model performance on validation set**","metadata":{}},{"cell_type":"code","source":"preds = model.predict(valid_x)\ndecoded = K.get_value(K.ctc_decode(preds, input_length=np.ones(preds.shape[0])*preds.shape[1], \n                                   greedy=True)[0][0])\n\nprediction = []\nfor i in range(valid_size):\n    prediction.append(num_to_label(decoded[i]))","metadata":{},"execution_count":null,"outputs":[]}]}